what a pain memory ...



## 初识算法

初识nmb，恶臭玩意，纯💩



## 复杂度分析

### 算法效率评估

1. 找到解法
2. 最优解法
   - 时间效率（算法运行时间的长短）
   - 空间效率（算法占用内存空间的大小）

### 效率估算方法

#### 实际测试

直接运行程序。但不同算法在不同硬件条件下（如单核 & 多核CPU）测试结果会不同；同时，需要大量数据，消耗计算资源

#### 理论估算

通过计算来估算算法效率，这种估算方法叫**复杂度分析**（描述了随着输入数据大小的增加，算法执行所需时间和空间的增长趋势，时间即指时间复杂度，空间即指空间复杂度）



### 迭代与递归

#### 插入讲迭代递归的原因

*在算法中，重复执行某个任务是很常见的，它与复杂度分析息息相关。因此，在介绍时间复杂度和空间复杂度之前，我们先来了解在程序中实现重复执行任务的两种基本的程序控制结构：迭代、递归*



#### 迭代

迭代（iteration）是一种重复执行某个任务的控制结构。*在迭代中，程序会在满足一定的条件下重复执行某段代码，直到这个条件不再满足*，即**循环**



##### for循环

*`for` 循环是最常见的迭代形式之一，**适合在预先知道迭代次数时使用***

例子：

```js
function forloop(n){
    let res = 0;
    for(let i = 1; i <= n; i++){
        res += i;
    }
    return res;
}
```

```python
def forloop(n):
    res = 0
    for i in range (1, n + 1):
        res += i
    return res
```



##### while循环

*与 `for` 循环类似，`while` 循环也是一种实现迭代的方法。在 `while` 循环中，**程序每轮都会先检查条件**，如果条件为真，则继续执行，否则就结束循环*

例子：

```js
function whileloop(n){
    let res = 0;
    let i = 1;
    while (i <= n){
        res += i;
        i++;
    }
    return res;
}
```

```py
def whileloop:
    res = 0
    while i <= 0:
        res += i
        i += 1
    return res
```



##### 嵌套循环

*一个循环结构内嵌套另一个循环结构*

例子：

```js
function nested_forloop(n){
    res = 0;
    for(let i = 0; i <= n; i++){
        for(let j = 0; j <= n; j++){
            res += i;
        }
    }
    return res;
}
```

```py
def nested_forloop(n):
    res = 0
    for i in range(0, n):
        for j in range(0, n):
            res += j
    return res        
```



#### 递归

##### 普通递归

递归（recursion）是一种算法策略，通过函数调用自身来解决问题。

1. 递归主要包含递和归两个阶段：

   - 递

     程序不断深入地调用自身，通常传入更小或更简化的参数，直到达到“终止条件”

   - 归

     触发“终止条件”后，程序从最深层的递归函数开始**逐层**返回，汇聚每一层的结果

2. 递归代码主要包含三个要素：

   - **终止条件**：用于决定什么时候由“递”转“归”。
   - **递归调用**：对应“递”，函数调用自身，通常输入更小或更简化的参数。
   - **返回结果**：对应“归”，将当前递归层级的结果返回至上一层（即```return```）

例子：（*以一个**普通递归**为例介绍递归的基本思想*）

```js
function recur(n){
    if (n === 1) return 1;
    const res = recur(n - 1); // 递
    return n + res; // 归
}
```

```py
def recur(n: int) -> int:
    if n == 1:
        return 1
    res = recur(n - 1) # 递
    return n + res # 归

# 以下是对上面python代码的分步详解
def recur(4):
    if n == 1:
        return 1
    else:
    res = recur(3) # n = 4		
          recur(3):
        	res = recur(2) # n = 3
            	  recur(2):
                    res = recur(1) # n = 2
                          recur(1):
                            res = recur(0) # n = 1
    						if n == 1:
    							return 1
                    res = recur(1) = 1 # n = 2
                    return n + res = 2 + 1 =3
             res = recur(2) = 3 # n = 3
             return n + res = 3 + (2 + 1) = 6
    res = recur(3) = 6 # n = 4   
    return n + recur = 4 + (3 + (2 + 1)) = 10        
    
Thus，recur(4) = 10
```



##### 尾递归

###### 普通递归的缺点

*在介绍尾递归前，有必要解释**普通递归存在的问题**......*

普通递归函数每次调用自身时，系统都会为新开启的函数分配内存，以存储局部变量、调用地址和其他信息等。这将**导致时间和空间效率都不如迭代**：

- 函数的上下文数据都存储在称为“栈帧空间”的内存区域中，直至函数返回后才会被释放。因此，**递归通常比迭代更加耗费内存空间**。
- 递归调用函数会产生额外的开销。**因此递归通常比循环的时间效率更低**。

在触发终止条件前，同时存在 n 个未返回的递归函数，**递归深度为n**，在实际中，编程语言允许的递归深度通常是有限的，**过深的递归可能导致栈溢出错误**

**......而尾递归，则填补了普通递归的一些缺点......**



###### 介绍尾递归

**如果函数在返回前的最后一步进行递归调用**，则该函数可以被编译器或解释器优化，**使其在空间效率上与迭代相当**。这种情况被称为**尾递归（tail recursion）**

- **普通递归**：当函数返回到上一层级的函数后，需要继续执行代码，因此系统需要保存上一层调用的上下文。**求和操作是在“归”的过程中执行的，每层返回后都要再执行一次求和操作**
- **尾递归**：递归调用是函数返回前的最后一个操作，这意味着函数返回到上一层级后，无须继续执行其他操作，因此系统无须保存上一层函数的上下文。**求和操作是在“递”的过程中执行的**，在尾递归触发终止条件的时候就相当于完成了普通递归在“归”这个过程里的所有运算操作，“归”的过程只需返回结果即可

**注意：**

*许多编译器或解释器并不支持尾递归优化。例如，Python 默认不支持尾递归优化，因此即使函数是尾递归形式，仍然可能会遇到栈溢出问题*

例子：

```js
function tail_recur(n, res){
    if (n === 0) return res;
    return tail_recur(n - 1， res + n)
}
```

```py
def tail_recur(n, res):
    if n == 0:
        return res
    return tail_recur(n - 1, res + n)

# 以下是对上面python代码的分步详解
def tail_recur(4, res = 0): # n = 4, res = 0
    if n == 0:
        return res
    return tail_recur(4 - 1, 0 + 4) 
           tail_recur(3, 4): # n = 3, res = 4
           return tail_recur(3 - 1, 4 + 3)
                        tail_recur(2, 7): # n = 2, res = 7
                	      return tail_recur(2 - 1, 7 + 2)
                                    tail_recur(1, 9): # n = 1, res = 9
                                    return tail_recur(1 - 1, 9 + 1)
                        					  tail_recur(0, 10):
                                			   	if n == 0:
                                        			return res = 10       
Thus，tail_recur(4) = 10
```



##### 递归树

当处理与“分治”相关的算法问题时，递归往往比迭代的思路更加直观、代码更加易读

例子：

给定一个斐波那契数列0,1,1,2,3,5,8,13,..., 求该数列的第n个数字

```js
function fib(n){
    if (n === 1 || n === 2) return n - 1;
    const res = fib(n - 1) + fib(n - 2);
    return res;
}
```

```py
def fib(n):
    if n == 1 or n == 2:
        return n - 1
    res = fib(n - 1) + fib(n - 2)
    return res

# 以下是对上面python代码的分步详解
def fib(4):
  if n == 1 or n == 2:
    return n - 1
  res = fib(4 - 1) + fib(4 - 2)
        fib(3):
      		res = fib(3 - 1) + fib(3 - 2)
        			= fib(2) + fib(1)
          			fib(2):
              		return 1
              	fib(1):
                  return 0
              = 1  
		    fib(2):
          return 1
      = 2
Thus, fib(4) = 2      
```

观察以上代码，我们在函数内递归调用了两个函数，**这意味着从一个调用产生了两个调用分支**。如上图所示，这样不断递归调用下去，最终将产生一棵层数为 n 的**递归树（recursion tree）**



##### 递归的种类

**Linear Recursion**：每次函数调用最多产生一次新的递归调用，递归链是线性的。

**Binary Recursion**：每次函数调用产生两次新的递归调用，通常用于分治问题。

**Multiple Recursion**：每次函数调用产生多次新的递归调用，用于处理多个子问题



#### 迭代与递归的对比

表 2-1  迭代与递归特点对比

|          | 迭代                                   | 递归                                                         |
| :------: | :------------------------------------- | :----------------------------------------------------------- |
| 实现方式 | 循环结构                               | 函数调用自身                                                 |
| 时间效率 | 效率通常较高，无函数调用开销           | 每次函数调用都会产生开销                                     |
| 内存使用 | 通常使用固定大小的内存空间             | 累积函数调用可能使用大量的栈帧空间                           |
| 适用问题 | 适用于简单循环任务，代码直观、可读性好 | 适用于子问题分解，如树、图、分治、回溯等，代码结构简洁、清晰 |

虽然从计算角度看，迭代与递归可以得到相同的结果，**但它们代表了两种完全不同的思考和解决问题的范式**。

- **迭代**：**“自下而上”**地解决问题。从最基础的步骤开始，然后不断重复或累加这些步骤，直到任务完成
- **递归**：**“自上而下”**地解决问题。将原问题分解为更小的子问题，这些子问题和原问题具有相同的形式。接下来将子问题继续分解为更小的子问题，直到基本情况时停止（基本情况的解是已知的）

#### 迭代和递归的内在联系



学完栈再来



### 时间复杂度

#### 初识时间复杂度

我们一般不会去通过统计各种操作在某个平台的运行时间总和去获得一个算法的运行时间，这不合理也不现实，所以，我们引入**时间复杂度**

时间复杂度分析统计的不是算法运行时间，**而是算法运行时间随着数据量变大时的增长趋势**



#### 推算时间复杂度

##### 引入函数渐近上界

![截屏2024-09-14 09.57.08](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-14 09.57.08.png)



##### 推算方法

###### 统计操作数量

1. **忽略 T(n) 中的常数项**。因为它们都与 n 无关，所以对时间复杂度不产生影响。
2. **省略所有系数**。例如，循环 2n 次、5n+1 次等，都可以简化记为 n 次，因为 n 前面的系数对时间复杂度没有影响。
3. **循环嵌套时使用乘法**。总操作数量等于外层循环和内层循环操作数量之积，每一层循环依然可以分别套用第 `1.` 点和第 `2.` 点的技巧

例子：

```js
function algorithm(n) {
    let a = 1;  // +0（技巧 1）
    a = a + n;  // +0（技巧 1）
    // +n（技巧 2）
    for (let i = 0; i < 5 * n + 1; i++) {
        console.log(0);
    }
    // +n*n（技巧 3）
    for (let i = 0; i < 2 * n; i++) {
        for (let j = 0; j < n + 1; j++) {
            console.log(0);
        }
    }
}
```

以下公式展示了使用上述技巧前后的统计结果，两者推算出的时间复杂度都为 $\ O(n^2)$

$$
\begin{align*}
T(n) &= 2n(n+1)+(5n+1)+2\qquad完整公式\\ &= 2n^2+7n+3 \\ 
\\T(n)&= n^2+n\qquad\qquad\qquad\qquad\qquad简略公式
\end{align*}
$$


###### 判断函数渐近上界

**时间复杂度由$\ T(n)$ 中最高阶的项来决定**。这是因为在 n 趋于无穷大时，最高阶的项将发挥主导作用，其他项的影响都可以忽略

| 操作数量$\ T(n)$        | 时间复杂度 |
| :---------------------- | ---------- |
| 100000                  | $\ O(1)$   |
| $\ 3n+2$                | $\ O(n)$   |
| $\ 2n^2+3n+2$           | $\ O(n^2)$ |
| $n^3+10000n^2$          | $\ O(n^3)$ |
| $\ 2^n +10000n^{10000}$ | $\ O(2^n)$ |



###### 常见渐进上界类型的比较

$$
\begin{align*}
O(1)<O(log\,n)<O(n)<O(n\,log\,n)<O(n^2)<O(2^n)<O(n!)\\
常数阶<对数阶<线性阶<线性对数阶<平方阶<指数阶<阶乘阶\end{align*}
$$

![截屏2024-09-14 10.56.30](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-14 10.56.30.png)

*（各类型的例子很多会在后面提到所以这里不赘述）*



#### 最差、最佳、平均时间复杂度

**算法的时间效率往往不是固定的，而是与输入数据的分布有关**。假设输入一个长度为 n 的数组 `nums` ，其中 `nums` 由从 1 至 n 的数字组成，每个数字只出现一次；但元素顺序是随机打乱的，任务目标是返回元素 1 的索引。我们可以得出以下结论。

- 当 `nums = [?, ?, ..., 1]` ，即当末尾元素是 1 时，需要完整遍历数组，**达到最差时间复杂度 O(n)** 。
- 当 `nums = [1, ?, ?, ...]` ，即当首个元素为 1 时，无论数组多长都不需要继续遍历，**达到最佳时间复杂度 Ω(1)** 。

**“最差时间复杂度”对应函数渐近上界，使用大 O 记号表示。相应地，“最佳时间复杂度”对应函数渐近下界，用 Ω 记号表示：**

我们在实际中很少使用最佳时间复杂度，因为通常只有在很小概率下才能达到，可能会带来一定的误导性。**而最差时间复杂度更为实用，因为它给出了一个效率安全值**，让我们可以放心地使用算法。

从上述示例可以看出，最差时间复杂度和最佳时间复杂度只出现于“特殊的数据分布”，这些情况的出现概率可能很小，并不能真实地反映算法运行效率。相比之下，**平均时间复杂度可以体现算法在随机输入数据下的运行效率**，用 Θ 记号来表示。

对于部分算法，我们可以简单地推算出随机数据分布下的平均情况。比如上述示例，由于输入数组是被打乱的，因此元素 1 出现在任意索引的概率都是相等的，那么算法的平均循环次数就是数组长度的一半 n/2 ，平均时间复杂度为 Θ(n/2)=Θ(n) 。**但对于较为复杂的算法，计算平均时间复杂度往往比较困难，因为很难分析出在数据分布下的整体数学期望。在这种情况下，我们通常使用最差时间复杂度作为算法效率的评判标准**

*[ 可能由于 O 符号过于朗朗上口，因此我们常常使用它来表示平均时间复杂度。但从严格意义上讲，这种做法并不规范。在本书和其他资料中，若遇到类似“平均时间复杂度 O(n)”的表述，请将其直接理解为 Θ(n) ]* 



### 空间复杂度

#### 初识空间复杂度

空间复杂度（space complexity）用于衡量算法占用内存空间随着数据量变大时的增长趋势。这个概念与时间复杂度非常类似，只需将“运行时间”替换为“占用内存空间”



#### 算法运行的内存空间类型

算法在运行过程中使用的内存空间主要包括以下几种：

- **输入空间**：用于存储算法的输入数据。
- **暂存空间**：用于存储算法在运行过程中的变量、对象、函数上下文等数据。
  - **暂存数据**：用于保存算法运行过程中的各种常量、变量、对象等。
  - **栈帧空间**：用于保存调用函数的上下文数据。系统在每次调用函数时都会在栈顶部创建一个栈帧，函数返回后，栈帧空间会被释放。
  - **指令空间**：用于保存编译后的程序指令，在实际统计中通常忽略不计。
- **输出空间**：用于存储算法的输出数据。

在分析一段程序的空间复杂度时，**我们通常统计<u>暂存数据、栈帧空间和输出数据</u>三部分**

例子：

```javascript
class Node{
  val;
  next;
  constructor(val){
    this.val = val ===undefined ? 0 : val;
    this.next = null;
  }
}

function constructorFunction{
  return 0;
}

function algorithm(n){            // 输入数据
 const a = 0;                     // 暂存数据（常量）
 let b = 0;                       // 暂存数据（常量）
 let node = Node(0);              // 暂存数据（对象）
 const c = constructorFunction(); // 栈帧空间（调用函数）
 return a + b + c;                // 输出数据
}
```



#### 推算方法（在时间复杂度基础上）

##### 与时间复杂度推算方法的不同点

**空间复杂度的推算方法与时间复杂度大致相同**，只需将统计对象从“操作数量”转为“使用空间大小”。且**我们通常只关注最差空间复杂度**。这是因为内存空间是一项硬性要求，我们必须确保在所有输入数据下都有足够的内存空间预留。

这里最差空间复杂度中的“最差”有两层含义。

1. **以最差输入数据为准**：当 n<10 时，空间复杂度为 O(1) ；但当 n>10 时，初始化的数组 `nums` 占用 O(n) 空间，因此最差空间复杂度为 O(n) 。
2. **以算法运行中的峰值内存为准**：例如，程序在执行最后一行之前，占用 O(1) 空间；当初始化数组 `nums` 时，程序占用 O(n) 空间，因此最差空间复杂度为 O(n) 。

例子：

```js
function algorithm(n) {
    const a = 0;                   // O(1)
    const b = new Array(10000);    // O(1)
    if (n > 10) {
        const nums = new Array(n); // O(n)
    }
}
```

**在递归函数中，需要注意统计栈帧空间:**

```js
function constFunc() {
    // 执行某些操作
    return 0;
}
/* 循环的空间复杂度为 O(1) */
function loop(n) {
    for (let i = 0; i < n; i++) {
        constFunc();
    }
}
/* 递归的空间复杂度为 O(n) */
function recur(n) {
    if (n === 1) return;
    return recur(n - 1);
}
```

函数 `loop()` 和 `recur()` 的时间复杂度都为 O(n) ，但空间复杂度不同。

- 函数 `loop()` 在循环中调用了 n 次 `function()` ，每轮中的 `function()` 都返回并释放了栈帧空间，因此空间复杂度仍为 O(1) 。
- 递归函数 `recur()` 在运行过程中会同时存在 n 个未返回的 `recur()` ，从而占用 O(n) 的栈帧空间。



##### 常见类型

$$
\begin{align*}
 O(1)<O(log\ n)< O(n)< O(n^2)<O(2^n)\\
 常数阶<对数阶<线性阶<平方阶<指数阶
\end{align*}
$$

![截屏2024-09-17 23.32.17](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-17 23.32.17.png)

*（各类型的例子很多会在后面提到所以这里不赘述）*



### 权衡时间和空间

理想情况下，我们希望算法的时间复杂度和空间复杂度都能达到最优。然而在实际情况中，同时优化时间复杂度和空间复杂度通常非常困难。

**降低时间复杂度通常需要以提升空间复杂度为代价，反之亦然**。我们将牺牲内存空间来提升算法运行速度的思路称为“以空间换时间”；反之，则称为“以时间换空间”。

选择哪种思路取决于我们更看重哪个方面。**在大多数情况下，时间比空间更宝贵**，因此“以空间换时间”通常是更常用的策略。当然，**在数据量很大的情况下，控制空间复杂度也非常重要。**



## 数据结构与数据类型



### 数据结构的分类

#### 分类角度1：逻辑结构

##### 线性数据结构

数组，链表，栈，队列，哈希表，元素间一对一的顺序关系

##### 非线性数据结构

###### 树形结构

树，堆，哈希表，元素间是一对多的关系

###### 网状结构

图，元素间是多对多的关系

![截屏2024-09-19 10.48.45](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-19 10.48.45.png)



#### 分类角度2：物理结构

说物理结构前，必须引入一点**内存**的知识，当算法程序运行时，正在处理的数据主要存储在内存中，为了方便理解，可以将内存看作一个Excel表格，表格的每个单元能储存一定大小的数据，**物理结构反映了数据在计算机内存中的存储方式，可分为连续空间存储（数组）和分散空间存储（链表）。物理结构从底层决定了数据的访问、更新、增删等操作方法**

![截屏2024-09-19 11.29.24](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-19 11.29.24.png)

值得说明的是，**所有数据结构都是基于数组、链表或二者的组合实现的**。例如，栈和队列既可以使用数组实现，也可以使用链表实现；而哈希表的实现可能同时包含数组和链表。

- **基于数组可实现**：栈、队列、哈希表、树、堆、图、矩阵、张量（维度 ≥3 的数组）等。
- **基于链表可实现**：栈、队列、哈希表、树、堆、图等。

（链表在初始化后，仍可以在程序运行过程中对其长度进行调整，因此也称“动态数据结构”。数组在初始化后长度不可变，因此也称“静态数据结构”。值得注意的是，数组可通过重新分配内存实现长度变化，从而具备一定的“动态性”。）



### 基本数据类型

为什么要在这里插入介绍数据类型？基本数据类型与数据结构之间有什么联系呢？我们知道，数据结构是在计算机中组织与存储数据的方式。这句话的主语是“结构”而非“数据”。换句话说，**基本数据类型提供了数据的“内容类型”，而数据结构提供了数据的“组织方式”**。

如果想表示“一排数字”，我们自然会想到使用数组。这是因为数组的线性结构可以表示数字的相邻关系和顺序关系，但至于存储的内容是整数 `int`、小数 `float` 还是字符 `char` ，则与“数据结构”无关。

所以，有必要在这里介绍基本数据类型

**基本数据类型是 CPU 可以直接进行运算的类型**，在算法中直接被使用，主要包括以下几种。

- 整数类型 `byte`、`short`、`int`、`long` 。
- 浮点数类型 `float`、`double` ，用于表示小数。
- 字符类型 `char` ，用于表示各种语言的字母、标点符号甚至表情符号等。
- 布尔类型 `bool` ，用于表示“是”与“否”判断。

**基本数据类型以二进制的形式存储在计算机中**。一个二进制位即为 1 比特。在绝大多数现代操作系统中，1 字节（byte）由 8 比特（bit）组成。

*（ 各种编程语言里不同基本数据类型占用空间，取值范围和默认值等可以在需要时查询 ）*



**以上就是对数据结构的一个总览，下面我们就要走进真正对数据结构的详细介绍**



## 数组与链表



### 数组

#### 初识数组

数组（array）是一种线性数据结构，其将相同类型的元素存储在连续的内存空间中。我们将元素在数组中的位置称为该元素的索引（index）

![截屏2024-09-19 16.01.53](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-19 16.01.53.png)



#### 数组常用操作

##### 初始化数组

可以根据需求选用数组的两种初始化方式：无初始值、给定初始值。在未指定初始值的情况下，大多数编程语言会将数组元素初始化为 0 

```js
const arr = new Array(5).fill(0);
let nums = [1, 3, 2, 5, 4];
```



##### 访问元素

在数组中访问元素非常高效，可以在 $O(1)$ 时间内随机访问数组中的任意元素，这是因为它的所有元素在内存中是连续存储的，并且每个元素的长度固定。而且在现代计算机中，内存地址的计算非常快速，硬件直接支持通过基地址和偏移量来获取内存中的数据（即下方图片里的公式），CPU 可以直接根据索引快速定位到目标元素的内存地址，无需遍历或查找，因此访问效率极高。

![截屏2024-09-19 16.33.54](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-19 16.33.54.png)

*（观察上图  ，我们发现数组首个元素的索引为 0 ，这似乎有些反直觉，因为从 1 开始计数会更自然。但从地址计算公式的角度看，**索引本质上是内存地址的偏移量**。首个元素的地址偏移量是 0 ，因此它的索引为 0 是合理的）*

例子：

```js
// 一个随机访问数组任意一个元素的函数
function random(nums){
  const random_num = nums[Math.floor(Math.random() * nums.length)]; // 先生成[0, 1)之间的随机小数再扩展到[0, nums.length)的范围，然后在用floor去掉小数 
  return random_num;
}
```



##### 插入元素

数组元素在内存中是“紧挨着的”，它们之间没有空间再存放任何数据。如图 4-3 所示，如果想在数组中间插入一个元素，则需要将该元素之后的所有元素都向后移动一位，之后再把元素赋值给该索引。值得注意的是，由于数组的长度是固定的，因此插入一个元素必定会导致数组尾部元素“丢失”。我们将这个问题的解决方案留在“列表”章节中讨论。

![截屏2024-09-20 14.42.20](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-20 14.42.20.png)

例子：

```js
function insert(nums, num, index){
  for (let i = nums.length - 1; i > index; i--){
    num[i] = nums[i - 1];
  }
  nums[index] = num;
}
```



##### 删除元素

若想删除索引 i 处的元素，则需要把索引 i 之后的元素都向前移动。删除元素完成后，原先末尾的元素变得“无意义”了，所以我们无须特意去修改它。![截屏2024-09-20 15.05.00](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-20 15.05.00.png)

例子：

```js
function remove(nums, index){
  for (let i = index; i < nums.length - 1; i++){
    nums[i] = nums [i + 1];
  }
}
```



##### 插入与删除的缺点

总的来看，数组的插入与删除操作有以下缺点。

- **时间复杂度高**：数组的插入和删除的平均时间复杂度均为 $O(n)$ ，其中 n 为数组长度。

- **丢失元素**：由于数组的长度不可变，因此在插入元素后，超出数组长度范围的元素会丢失。

- **内存浪费**：我们可以初始化一个比较长的数组，只用前面一部分，这样在插入数据时，丢失的末尾元素都是“无意义”的，但这样做会造成部分内存空间浪费。

  

##### 遍历数组与查找元素

在大多数编程语言中，我们既可以通过索引遍历数组，也可以直接遍历获取数组中的每个元素：

例子：

```js
// 一个函数将数组里面数字遍历后总和计入count
function traverse(nums){
  let count = 0;
  // 通过索引遍历数组
  for(let i = 0; i < nums.length; i++){
    count += nums[i];
  }
  
  // 直接遍历数组元素
  for (const num of nums){
    count += num;
  }
}
```



在数组中查找指定元素需要遍历数组，每轮判断元素值是否匹配，若匹配则输出对应索引。因为数组是线性数据结构，所以上述查找操作被称为**“线性查找”**。

例子：

```js
function find(nums, target){
  for (let i = 0; i < nums.length; i++){
    if (nums[i] === target) return i; 
  }
  return -1; // 常见的一种用来表示没有找到目标值的写法
}
```



##### 扩容数组

在复杂的系统环境中，程序难以保证数组之后的内存空间是可用的，从而无法安全地扩展数组容量。因此在大多数编程语言中，**数组的长度是不可变的**。

如果我们希望扩容数组，则需重新建立一个更大的数组，然后把原数组元素依次复制到新数组。这是一个$O(n)$ 的操作，在数组很大的情况下非常耗时。

例子：

```js
function extend(nums, enlarge){
  const res = Array(nums.length + enlarge).fill(0);
  for (let i = 0; i < nums.length; i++){
    res[i] = nums[i];
  }
  return res;
}
```



#### 数组的优缺点

数组存储在连续的内存空间内，且元素类型相同。这种做法包含丰富的先验信息，系统可以利用这些信息来优化数据结构的操作效率。

- **空间效率高**：数组为数据分配了连续的内存块，无须额外的结构开销。
- **支持随机访问**：数组允许在 O(1) 时间内访问任何元素。
- **缓存局部性**：当访问数组元素时，计算机不仅会加载它，还会缓存其周围的其他数据，从而借助高速缓存来提升后续操作的执行速度。

连续空间存储是一把双刃剑，其存在以下局限性。

- **插入与删除效率低**：当数组中元素较多时，插入与删除操作需要移动大量的元素。
- **长度不可变**：数组在初始化后长度就固定了，扩容数组需要将所有数据复制到新数组，开销很大。
- **空间浪费**：如果数组分配的大小超过实际所需，那么多余的空间就被浪费了。



#### 数组的应用

数组是一种基础且常见的数据结构，既频繁应用在各类算法之中，也可用于实现各种复杂数据结构。

- **随机访问**：如果我们想随机抽取一些样本，那么可以用数组存储，并生成一个随机序列，根据索引实现随机抽样。
- **排序和搜索**：数组是排序和搜索算法最常用的数据结构。快速排序、归并排序、二分查找等都主要在数组上进行。
- **查找表**：当需要快速查找一个元素或其对应关系时，可以使用数组作为查找表。假如我们想实现字符到 ASCII 码的映射，则可以将字符的 ASCII 码值作为索引，对应的元素存放在数组中的对应位置。
- **机器学习**：神经网络中大量使用了向量、矩阵、张量之间的线性代数运算，这些数据都是以数组的形式构建的。数组是神经网络编程中最常使用的数据结构。
- **数据结构实现**：数组可以用于实现栈、队列、哈希表、堆、图等数据结构。例如，图的邻接矩阵表示实际上是一个二维数组。



### 链表



#### 初识链表

存储数组的内存空间必须是连续的，而当数组非常大时，内存可能无法提供如此大的连续空间。此时链表的灵活性优势就体现出来了。链表（linked list）是一种线性数据结构，其中的每个元素都是一个节点对象，各个节点通过“引用”相连接。引用记录了下一个节点的内存地址，通过它可以从当前节点访问到下一个节点。链表的设计使得各个节点可以分散存储在内存各处，它们的内存地址无须连续。

![截屏2024-09-23 11.43.38](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-23 11.43.38.png)

链表的组成单位是节点（node）对象。每个节点都包含两项数据：节点的“值”和指向下一节点的“引用”。因此在相同数据量下，**链表比数组占用更多的内存空间**。

- 链表的首个节点被称为“头节点”，最后一个节点被称为“尾节点”。
- 尾节点指向的是“空”，它在 Java、C++ 和 Python 中分别被记为 `null`、`nullptr` 和 `None` 。
- 在 C、C++、Go 和 Rust 等支持指针的语言中，上述“引用”应被替换为“指针”。



#### 链表常用操作

##### 初始化链表

建立链表分为两步，第一步是初始化各个节点对象，第二步是构建节点之间的引用关系。初始化完成后，我们就可以从链表的头节点出发，通过引用指向 `next` 依次访问所有节点。

```js
// 初始化各个节点
const n0 = new ListNode(1);
const n1 = new ListNode(2);
const n2 = new ListNode(3);
const n3 = new ListNode(4);
const n4 = new ListNode(5);
// 构建指针(引用)
n0.next = n1;
n1.next = n2;
n2.next = n3;
n3.next = n4;
```



##### 插入节点

在链表中插入节点非常容易。如图 4-6 所示，假设我们想在相邻的两个节点 `n0` 和 `n1` 之间插入一个新节点 `P` ，**则只需改变两个节点引用（指针）即可**，时间复杂度为 $O(1)$ 相比之下，在数组中插入元素的时间复杂度为 $O(n)$ ，在大数据量下的效率较低。

![截屏2024-09-23 11.56.45](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-23 11.56.45.png)

```js
function insert(n0, P){
  const n1 = n0.next; // 定义n1
  // 下面是插入操作（本质就是将下一个节点的值赋给上一个节点的指针）
  P.next = n1; 
  n0.next = P;
}
```



##### 删除节点

在链表中删除节点也非常方便，**只需改变一个节点的引用（指针）即可**。

![截屏2024-09-23 13.09.59](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-23 13.09.59.png)

```js
function remove(n0){
  if (!n0.next) return;
  const P = n0.next;
  const n1 = P.next;
  // 下面是删除的操作，相当于一种特殊的插入
  n0.next = n1;
}
```



##### 访问节点

**在链表中访问节点的效率较低**。如上一节所述，我们可以在 $O(1)$ 时间下访问数组中的任意元素。链表则不然，程序需要从头节点出发，逐个向后遍历，直至找到目标节点。也就是说，访问链表的第 i 个节点需要循环 $i−1$ 轮，时间复杂度为 $O(n)$ 。

```js
function access(head, index){
  for (let i = 0; i < index; i++){
    // 检查head是否为空，即链表是否已经遍历完了到尾部了，如果确实到尾部了那就说明不存在该索引的节点
    if (!head){
      return null;
    }
    head = head.next;
  }
  return head;
}
```



##### 查找节点

遍历链表，查找其中值为 `target` 的节点，输出该节点在链表中的索引。此过程也属于线性查找。

```js
function find(head, target){
  let index = 0;
  while (head !== null){
    if (head.val === target){
      return index;
    }
    head = head.next;
    index += 1;
  }
  return -1;
}
```





#### 常见链表类型

常见的链表类型包括三种

- **单向链表**：即前面介绍的普通链表。单向链表的节点包含值和指向下一节点的引用两项数据。我们将首个节点称为头节点，将最后一个节点称为尾节点，尾节点指向空 `None` 。
- **环形链表**：如果我们令单向链表的尾节点指向头节点（首尾相接），则得到一个环形链表。在环形链表中，任意节点都可以视作头节点。
- **双向链表**：与单向链表相比，双向链表记录了两个方向的引用。双向链表的节点定义同时包含指向后继节点（下一个节点）和前驱节点（上一个节点）的引用（指针）。相较于单向链表，双向链表更具灵活性，可以朝两个方向遍历链表，但相应地也需要占用更多的内存空间。

![截屏2024-09-23 14.24.10](/Users/aris/Library/Application Support/typora-user-images/截屏2024-09-23 14.24.10.png)



#### 链表的应用

单向链表通常用于实现栈、队列、哈希表和图等数据结构。

- **栈与队列**：当插入和删除操作都在链表的一端进行时，它表现的特性为先进后出，对应栈；当插入操作在链表的一端进行，删除操作在链表的另一端进行，它表现的特性为先进先出，对应队列。
- **哈希表**：链式地址是解决哈希冲突的主流方案之一，在该方案中，所有冲突的元素都会被放到一个链表中。
- **图**：邻接表是表示图的一种常用方式，其中图的每个顶点都与一个链表相关联，链表中的每个元素都代表与该顶点相连的其他顶点。

双向链表常用于需要快速查找前一个和后一个元素的场景。

- **高级数据结构**：比如在红黑树、B 树中，我们需要访问节点的父节点，这可以通过在节点中保存一个指向父节点的引用来实现，类似于双向链表。
- **浏览器历史**：在网页浏览器中，当用户点击前进或后退按钮时，浏览器需要知道用户访问过的前一个和后一个网页。双向链表的特性使得这种操作变得简单。
- **LRU 算法**：在缓存淘汰（LRU）算法中，我们需要快速找到最近最少使用的数据，以及支持快速添加和删除节点。这时候使用双向链表就非常合适。

环形链表常用于需要周期性操作的场景，比如操作系统的资源调度。

- **时间片轮转调度算法**：在操作系统中，时间片轮转调度算法是一种常见的 CPU 调度算法，它需要对一组进程进行循环。每个进程被赋予一个时间片，当时间片用完时，CPU 将切换到下一个进程。这种循环操作可以通过环形链表来实现。
- **数据缓冲区**：在某些数据缓冲区的实现中，也可能会使用环形链表。比如在音频、视频播放器中，数据流可能会被分成多个缓冲块并放入一个环形链表，以便实现无缝播放。



### 数组与链表的对比

表 4-1  数组与链表的效率对比

|                | 数组                           | 链表           |
| :------------- | :----------------------------- | :------------- |
| 存储方式       | 连续内存空间                   | 分散内存空间   |
| 容量扩展       | 长度不可变                     | 可灵活扩展     |
| 内存效率       | 元素占用内存少、但可能浪费空间 | 元素占用内存多 |
| 访问元素       | $O(1)$                         | $O(n)$         |
| 插入元素       | $O(n)$                         | $O(1)$         |
| 删除元素       | $O(n)$                         | $O(1)$         |
| 遍历与查找元素 | $O(n)$                         | $O(n)$         |

*数组与链表产生各自特点的区别的根本原因就是储存方式的不同，数组连续内存空间导致其拥有快速访问的特点但失去了快速添加和删除的能力，而链表则刚好相反*



### 列表

#### 定义区分：列表/数组/静态数组/动态数组

列表（list）是一个抽象的数据结构概念，它表示元素的有序集合，支持元素访问、修改、添加、删除和遍历等操作，无须使用者考虑容量限制的问题。列表可以基于链表或数组实现。

实际上，**许多编程语言中的标准库提供的列表是基于动态数组实现的**，例如 Python 中的 `list` 、Java 中的 `ArrayList` 、C++ 中的 `vector` 和 C# 中的 `List` 等。**所以在很多情况下，我们将把 “列表 ”和 “动态数组 ”视为等同的概念。**

**在一些编程语言的初始设定里，是明确区分静态数组和动态数组的，比如 C, C++, C#, Java, Go 等**，这些语言里需要我们手动选择哪种使用

**另外，在一些编程语言的初始设定里，没有静态数组或普通数组）的设计，比如 JavaScript,  Python等**，在这些语言里，数组，列表，静态数组，动态数组都可以被认为是一个东西，创建方式也一模一样。（当然，Python可以痛通过array模块或NumPy库来实现静态数组，但这不是初始设定）



#### 列表常用操作

##### 初始化列表

```js
const nums1 = [];
const nums = [1, 3, 2, 5, 4];
```



##### 访问元素

列表本质上是数组，因此可以在 $O(1)$ 时间内访问和更新元素，效率很高。

```js
const num = num[1];
num[1] = 0;
```



##### 插入与删除元素

相较于数组，列表可以自由地添加与删除元素。在列表尾部添加元素的时间复杂度为 $O(1)$ ，但插入和删除元素的效率仍与数组相同，时间复杂度为 $O(n)$ 

```js
/* 清空列表 */
nums.length = 0;

/* 在尾部添加元素 */
nums.push(1);
nums.push(3);
nums.push(2);
nums.push(5);
nums.push(4);

/* 在中间插入元素 */
nums.splice(3, 0, 6); // 在索引 3 处插入数字 6, 0是指删除0个元素即不删除任何元素

/* 删除元素 */
nums.splice(3, 1);  // 删除索引 3 处的元素
```



##### 遍历列表

与数组一样，列表可以根据索引遍历，也可以直接遍历各元素

```py
count = 0
for i in range(len(nums)):
  count += number[i]
for num in nums:
  count += num
```



##### 拼接列表

```py
nums1:list[int] = [6, 8, 7, 10,9]
nums += nums1 #拼接 nums1 到 nums 后
```



##### 排序列表

```py
nums.sort()
```







## 栈与队列



### 栈

#### 初识栈

栈（stack）是一种遵循先入后出逻辑的线性数据结构，如图所示，我们把堆叠元素的顶部称为“栈顶”，底部称为“栈底”。将把元素添加到栈顶的操作叫作“入栈”，删除栈顶元素的操作叫作“出栈”

![截屏2024-10-07 15.11.05](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-07 15.11.05.png)



#### 栈的常用操作

| 方法     | 描述                   | 时间复杂度 |
| :------- | :--------------------- | :--------- |
| `push()` | 元素入栈（添加至栈顶） | $O(1)$     |
| `pop()`  | 栈顶元素出栈           | $O(1)$     |
| `peek()` | 访问栈顶元素           | $O(1)$     |



通常情况下，我们可以直接使用编程语言内置的栈类。然而，某些语言（如：Python, C,  javascript,  Go,  Rust）可能没有专门提供栈类，这时我们可以将该语言的“数组”或“链表”当作栈来使用，并在程序逻辑上忽略与栈无关的操作

```python
# 初始化栈
stack = []

# 元素入栈
stack.append(1)
stack.append(2)

# 访问栈顶元素
peek = stack[-1]

# 元素出栈
pop = stack.pop()

# 获取栈的长度
size = len(stack)

# 判断是否为空
is_empty = len(stack) == 0
```



#### 栈的实现

##### 基于链表的实现

使用链表实现栈时，我们可以将链表的头节点视为栈顶，尾节点视为栈底。

如图所示，对于入栈操作，我们只需将元素插入链表头部，这种节点插入方法被称为“头插法”。而对于出栈操作，只需将头节点从链表中删除即可

![截屏2024-10-07 16.27.08](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-07 16.27.08.png)

![截屏2024-10-07 16.27.20](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-07 16.27.20.png)



##### 基于数组的实现

使用数组实现栈时，我们可以将数组的尾部作为栈顶。如图所示，入栈与出栈操作分别对应在数组尾部添加元素与删除元素，时间复杂度都为 O(1) 

![截屏2024-10-07 16.29.29](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-07 16.29.29.png)

![截屏2024-10-07 16.29.45](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-07 16.29.45.png)



##### 两种实现的对比

时间效率：

在基于数组的实现中，入栈和出栈操作都在预先分配好的连续内存中进行，具有很好的缓存本地性，因此效率较高。然而，如果入栈时超出数组容量，会触发扩容机制，导致该次入栈操作的时间复杂度变为 $O(n)$ 。

在基于链表的实现中，链表的扩容非常灵活，不存在上述数组扩容时效率降低的问题。但是，入栈操作需要初始化节点对象并修改指针，因此效率相对较低。不过，如果入栈元素本身就是节点对象，那么可以省去初始化步骤，从而提高效率。

- 基于数组实现的栈在触发扩容时效率会降低，但由于扩容是低频操作，因此只能说平均效率更高。
- 基于链表实现的栈可以提供更加稳定的效率表现。

空间效率：

在初始化列表时，系统会为列表分配“初始容量”，该容量可能超出实际需求；并且，扩容机制通常是按照特定倍率（例如 2 倍）进行扩容的，扩容后的容量也可能超出实际需求。因此，**基于数组实现的栈可能造成一定的空间浪费**。

然而，由于链表节点需要额外存储指针，**因此链表节点占用的空间相对较大**。



#### 栈的应用

- **浏览器中的后退与前进、软件中的撤销与反撤销**。每当我们打开新的网页，浏览器就会对上一个网页执行入栈，这样我们就可以通过后退操作回到上一个网页。后退操作实际上是在执行出栈。如果要同时支持后退和前进，那么需要两个栈来配合实现。
- **程序内存管理**。每次调用函数时，系统都会在栈顶添加一个栈帧，用于记录函数的上下文信息。在递归函数中，向下递推阶段会不断执行入栈操作，而向上回溯阶段则会不断执行出栈操作。





### 队列

#### 初识队列

队列（queue）是一种遵循先入先出规则的线性数据结构。顾名思义，队列模拟了排队现象，即新来的人不断加入队列尾部，而位于队列头部的人逐个离开。

如图所示，我们将队列头部称为“队首”，尾部称为“队尾”，将把元素加入队尾的操作称为“入队”，删除队首元素的操作称为“出队”

![截屏2024-10-07 16.53.44](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-07 16.53.44.png)



#### 队列的常用操作

需要注意的是，不同编程语言的方法名称可能会有所不同。我们在此采用与栈相同的方法命名

| 方法名   | 描述                         | 时间复杂度 |
| :------- | :--------------------------- | :--------- |
| `push()` | 元素入队，即将元素添加至队尾 | $O(1)$     |
| `pop()`  | 队首元素出队                 | $O(1)$     |
| `peek()` | 访问队首元素                 | $O(1)$     |



```python
from collections import deque

# 初始化队列
# 在 Python 中，我们一般将双向队列类 deque 当作队列使用
# 虽然 queue.Queue() 是纯正的队列类，但不太好用，因此不推荐
que: deque[int] = deque()

# 元素入队
que.append(1)
que.append(3)

# 访问队首元素
front = que[0]

# 元素出队
pop = que.popleft()

# 获取队列的长度
size = len(que)

# 判断队列是否为空
is_empty = len(que) == 0
```





#### 队列的实现

##### 基于链表的实现

如图所示，我们可以将链表的“头节点”和“尾节点”分别视为“队首”和“队尾”，规定队尾仅可添加节点，队首仅可删除节点

![截屏2024-10-07 17.04.41](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-07 17.04.41.png)

![截屏2024-10-07 17.04.56](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-07 17.04.56.png)



##### 基于数组的实现

在数组中删除首元素的时间复杂度为 $O(n)$ ，这会导致出队操作效率较低。然而，我们可以采用以下巧妙方法来避免这个问题

我们可以使用一个变量 `front` 指向队首元素的索引，并维护一个变量 `size` 用于记录队列长度。定义 `rear = front + size` ，这个公式计算出的 `rear` 指向队尾元素之后的下一个位置

基于此设计，**数组中包含元素的有效区间为 `[front, rear - 1]`**，各种操作的实现方法如图所示

- 入队操作：将输入元素赋值给 `rear` 索引处，并将 `size` 增加 1 
- 出队操作：只需将 `front` 增加 1 ，并将 `size` 减少 1 

可以看到，入队和出队操作都只需进行一次操作，时间复杂度均为 $O(1)$

![截屏2024-10-07 17.25.47](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-07 17.25.47.png)

![截屏2024-10-07 17.26.12](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-07 17.26.12.png)



你可能会发现一个问题：在不断进行入队和出队的过程中，`front` 和 `rear` 都在向右移动，**当它们到达数组尾部时就无法继续移动了**。为了解决此问题，我们可以将数组视为首尾相接的“环形数组”。

对于环形数组，我们需要让 `front` 或 `rear` 在越过数组尾部时，直接回到数组头部继续遍历。这种周期性规律可以通过“取余操作”来实现，代码太长，略



#### 队列的应用

- **淘宝订单** 购物者下单后，订单将加入队列中，系统随后会根据顺序处理队列中的订单。在双十一期间，短时间内会产生海量订单，高并发成为工程师们需要重点攻克的问题。
- **各类待办事项** 任何需要实现“先来后到”功能的场景，例如打印机的任务队列、餐厅的出餐队列等，队列在这些场景中可以有效地维护处理顺序。



**两种实现的对比结论与栈一致，在此不再赘述**





### 双向队列

#### 初识双向队列

在队列中，我们仅能删除头部元素或在尾部添加元素。如图所示，双向队列（double-ended queue）提供了更高的灵活性，允许在头部和尾部执行元素的添加或删除操作。

![截屏2024-10-07 18.27.31](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-07 18.27.31.png)



*双向队列的实现可以忽略不学，意义不大*



#### 双向队列的常用操作

双向队列的常用操作如表所示，具体的方法名称需要根据所使用的编程语言来确定

| 方法名         | 描述             | 时间复杂度 |
| :------------- | :--------------- | :--------- |
| `push_first()` | 将元素添加至队首 | $O(1)$     |
| `push_last()`  | 将元素添加至队尾 | $O(1)$     |
| `pop_first()`  | 删除队首元素     | $O(1)$     |
| `pop_last()`   | 删除队尾元素     | $O(1)$     |
| `peek_first()` | 访问队首元素     | $O(1)$     |
| `peek_last()`  | 访问队尾元素     | $O(1)$     |



```python
from collections import deque

# 初始化双向队列
deq: deque[int] = deque()

# 元素入队
deq.append(2)      # 添加至队尾
deq.append(5)
deq.append(4)
deq.appendleft(3)  # 添加至队首
deq.appendleft(1)

# 访问元素
front: int = deq[0]  # 队首元素
rear: int = deq[-1]  # 队尾元素

# 元素出队
pop_front: int = deq.popleft()  # 队首元素出队
pop_rear: int = deq.pop()       # 队尾元素出队

# 获取双向队列的长度
size: int = len(deq)

# 判断双向队列是否为空
is_empty: bool = len(deq) == 0
```



#### 双向队列的应用

双向队列兼具栈与队列的逻辑，**因此它可以实现这两者的所有应用场景，同时提供更高的自由度**





## 哈希表



### 初识哈希表

哈希表（hash table），又称散列表，它通过建立键 `key` 与值 `value` 之间的映射，实现高效的元素查询。具体而言，我们向哈希表中输入一个键 `key` ，则可以在 $O(1)$ 时间内获取对应的值 `value` 。

如图所示，给定 n 个学生，每个学生都有“姓名”和“学号”两项数据。假如我们希望实现“输入一个学号，返回对应的姓名”的查询功能，则可以采用图所示的哈希表来实现。

![截屏2024-10-08 20.11.52](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-08 20.11.52.png)



**另外，在哈希表中进行增删查改的时间复杂度都是 O(1)，下面是与其他数据结构的对比** 

|          | 数组 | 链表 | 哈希表 |
| :------- | :--- | :--- | :----- |
| 查找元素 | O(n) | O(n) | O(1)   |
| 添加元素 | O(1) | O(1) | O(1)   |
| 删除元素 | O(n) | O(1) | O(1)   |

*（注意添加元素是将元素添加至数组的尾部，使用 $O(1)$时间，与插入操作不一样）*



### 哈希表常用操作



#### 初始化与增删改查

```python
# 初始化哈希表
hmap = {}

# 添加
# 在哈希表中添加键值对 (key, value)
hmap[12836] = "小哈"
hmap[15937] = "小啰"

# 查询
# 向哈希表中输入键 key ，得到值 value
name = hmap[15937]

# 删除
# 在哈希表中删除键值对 (key, value)
hmap.pop(10583)

# 修改
hmap[15937] = "小喽"
```



#### 三种遍历方式

即：遍历键值对、遍历键和遍历值

```python
# 遍历键值对 key->value
for key, value in hmap.items():
    print(key, "->", value)

# 单独遍历键 key
for key in hmap.keys():
    print(key)

# 单独遍历值 value
for value in hmap.values():
    print(value)
```



### 基于数组实现的哈希表

我们先考虑最简单的情况，**仅用一个数组来实现哈希表**。在哈希表中，我们将数组中的每个空位称为桶（bucket），每个桶可存储一个键值对。因此，查询操作就是找到 `key` 对应的桶，并在桶中获取 `value` 。

*（注意：并不是所有的编程语言都支持用数组来储存键值对以实现哈希表，如 C, C++, Java, Go 等要声明变量类型的静态类型语言都不行）*

那么，如何基于 `key` 定位对应的桶呢？这是通过哈希函数（hash function）实现的。哈希函数的作用是将一个较大的输入空间映射到一个较小的输出空间。在哈希表中，输入空间是所有 `key` ，输出空间是所有桶（数组索引）。换句话说，输入一个 `key` ，**我们可以通过哈希函数得到该 `key` 对应的键值对在数组中的存储位置**。

输入一个 `key` ，哈希函数的计算过程分为以下两步。

1. 通过某种哈希算法 `hash()` 计算得到哈希值。
2. 将哈希值对桶数量（数组长度）`capacity` 取模，从而获取该 `key` 对应的数组索引 `index` 。

```
index = hash(key) % capacity
```

随后，我们就可以利用 `index` 在哈希表中访问对应的桶，从而获取 `value` 。

设数组长度 `capacity = 100`、哈希算法 `hash(key) = key` ，易得哈希函数为 `key % 100` 。下图以 `key` 学号和 `value` 姓名为例，展示了哈希函数的工作原理。

![截屏2024-10-08 21.05.51](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-08 21.05.51.png)



### 基于数组实现的哈希表存在的问题

从本质上看，哈希函数的作用是将所有 `key` 构成的输入空间映射到数组所有索引构成的输出空间，而输入空间往往远大于输出空间。因此，**理论上一定存在“多个输入对应相同输出”的情况**。

对于上述示例中的哈希函数，当输入的 `key` 后两位相同时，哈希函数的输出结果也相同。例如，查询学号为 12836 和 20336 的两个学生时，我们得到：

```
12836 % 100 = 36
20336 % 100 = 36
```

如图 6-3 所示，两个学号指向了同一个姓名，这显然是不对的。我们将这种多个输入对应同一输出的情况称为**哈希冲突（hash collision）**

![截屏2024-10-08 21.52.01](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-08 21.52.01.png)





### 基于数组实现的哈希表存在的问题的解决

#### 如何在哈希冲突时保持正常工作

##### 扩容哈希表

**通常情况下哈希函数的输入空间远大于输出空间**，因此理论上哈希冲突是不可避免的。比如，输入空间为全体整数，输出空间为数组容量大小，则必然有多个整数映射至同一桶索引。

哈希冲突会导致查询结果错误，严重影响哈希表的可用性。为了解决该问题，容易想到，哈希表容量 n 越大，多个 `key` 被分配到同一个桶中的概率就越低，冲突就越少。因此，**我们可以通过扩容哈希表来减少哈希冲突**。

如图所示，扩容前键值对 `(136, A)` 和 `(236, D)` 发生冲突，扩容后冲突消失

![截屏2024-10-08 21.52.42](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-08 21.52.42.png)

类似于数组扩容，哈希表扩容需将所有键值对从原哈希表迁移至新哈希表，非常耗时；并且由于哈希表容量 `capacity` 改变，我们需要通过哈希函数来重新计算所有键值对的存储位置，这进一步增加了扩容过程的计算开销。为此，编程语言通常会预留足够大的哈希表容量，防止频繁扩容。

负载因子（load factor）是哈希表的一个重要概念，其定义为哈希表的元素数量除以桶数量，用于衡量哈希冲突的严重程度，**也常作为哈希表扩容的触发条件**。例如在 Java 中，当负载因子超过 0.75 时，系统会将哈希表扩容至原先的 2 倍。



##### 采用链式寻址实现哈希表

在原始哈希表中，每个桶仅能存储一个键值对。链式地址（separate chaining）将单个元素转换为链表，将键值对作为链表节点，将所有发生冲突的键值对都存储在同一链表中。图展示了一个链式地址哈希表的例子

![截屏2024-10-09 09.00.53](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-09 09.00.53.png)

基于链式地址实现的哈希表的操作方法发生了以下变化。

- **查询元素**：输入 `key` ，经过哈希函数得到桶索引，即可访问链表头节点，然后遍历链表并对比 `key` 以查找目标键值对。
- **添加元素**：首先通过哈希函数访问链表头节点，然后将节点（键值对）添加到链表中。
- **删除元素**：根据哈希函数的结果访问链表头部，接着遍历链表以查找目标节点并将其删除。



链式地址存在以下局限性。

- **占用空间增大**：链表包含节点指针，它相比数组更加耗费内存空间。
- **查询效率降低**：因为需要线性遍历链表来查找对应元素。

值得注意的是，当链表很长时，查询效率 O(n) 很差。**此时可以将链表转换为“AVL 树”或“红黑树”**，从而将查询操作的时间复杂度优化至 O(log⁡n) 。



##### 采用开放寻址实现哈希表

开放寻址（open addressing）不引入额外的数据结构，而是通过“多次探测”来处理哈希冲突，探测方式主要包括线性探测、平方探测和多次哈希等。

###### 线性探测



**1. 线性探测是什么**

线性探测采用固定步长的线性搜索来进行探测，其操作方法与普通哈希表有所不同。

- **插入元素**：通过哈希函数计算桶索引，若发现桶内已有元素，则从冲突位置向后线性遍历（步长通常为 1 ），直至找到空桶，将元素插入其中。
- **查找元素**：若发现哈希冲突，则使用相同步长向后进行线性遍历，直到找到对应元素，返回 `value` 即可；如果遇到空桶，说明目标元素不在哈希表中，返回 `None` 。

下图展示了开放寻址（线性探测）哈希表的键值对分布。根据此哈希函数，最后两位相同的 `key` 都会被映射到相同的桶。而通过线性探测，它们被依次存储在该桶以及之下的桶中

![截屏2024-10-09 15.04.30](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-09 15.04.30.png)



**2. 线性探测的缺点**

然而，**线性探测容易产生“聚集现象”**。具体来说，数组中连续被占用的位置越长，这些连续位置发生哈希冲突的可能性越大，从而进一步促使该位置的聚堆生长，形成恶性循环，最终导致增删查改操作效率劣化。



###### 环形数组在开放寻址（线性探测）里的应用



**为了更加充分地使用哈希表的空间，我们将哈希表看作一个“环形数组”**，当越过数组尾部时，回到头部继续遍历。即当一个簇位于数组末，但现在需要插入一个新元素进入这个簇，如果不是环形数组，那这个插入操作就无法进行了，所以如果是环形数组，那么新的元素就可以插入到数组的开头即连续上末尾构成闭环。

但**并不是所有语言的哈希表实现都使用环形数组**，像Java, Go等采用链式寻址实现



###### 平方探测

平方探测与线性探测类似，都是开放寻址的常见策略之一。当发生冲突时，平方探测不是简单地跳过一个固定的步数，而是跳过“探测次数的平方”的步数，即 1,4,9,… 步。

平方探测主要具有以下优势。

- 平方探测通过跳过探测次数平方的距离，试图缓解线性探测的聚集效应。
- 平方探测会跳过更大的距离来寻找空位置，有助于数据分布得更加均匀。

然而，平方探测并不是完美的。

- 仍然存在聚集现象，即某些位置比其他位置更容易被占用。
- 由于平方的增长，平方探测可能不会探测整个哈希表，这意味着即使哈希表中有空桶，平方探测也可能无法访问到它。这会导致性能下降，因为这意味着需要更长的探测链来找到可用的桶。



###### 多次哈希

顾名思义，多次哈希方法使用多个哈希函数 f1(x)、f2(x)、f3(x)、… 进行探测。

- **插入元素**：若哈希函数 f1(x) 出现冲突，则尝试 f2(x) ，以此类推，直到找到空位后插入元素。
- **查找元素**：在相同的哈希函数顺序下进行查找，直到找到目标元素时返回；若遇到空位或已尝试所有哈希函数，说明哈希表中不存在该元素，则返回 `None` 。

与线性探测相比，多次哈希方法不易产生聚集，但多个哈希函数会带来额外的计算量。

例如：假设我们有一个哈希表的大小 N = 7，并且我们使用两个哈希函数：

​	• h1(key) = key % 7（模哈希）

​	• h2(key) = 1 + (key % 5)（步长哈希）

现在我们要插入以下几个键：10, 22, 31, 4, 15, 28。

​	1. **插入 10**：

​	•  h1(10) = 10 % 7 = 3，位置 3 为空，直接插入。

​	• 哈希表：[ - , - , - , 10, - , - , - ]

​	2. **插入 22**：

​	• h1(22) = 22 % 7 = 1，位置 1 为空，直接插入。

​	• 哈希表：[ - , 22, - , 10, - , - , - ]

​	3. **插入 31**：

​	• h1(31) = 31 % 7 = 3，位置 3 已经被 10 占用，发生冲突。

​	• 计算第二个哈希函数：h2(31) = 1 + (31 % 5) = 1 + 1 = 2。

​	• 使用多次哈希：第一次探测位置 3 + 1 * 2 = 5，位置 5 为空，插入成功。

​	• 哈希表：[ - , 22, - , 10, - , 31, - ]



###### 懒删除

*以线性探测为例*

值得注意的是，**我们不能在开放寻址哈希表中直接删除元素**。这是因为删除元素会在数组内产生一个空桶 `None` ，而当查询元素时，线性探测到该空桶就会返回，因此在该空桶之下的元素都无法再被访问到，程序可能误判这些元素不存在，如图所示。

![截屏2024-10-09 15.06.52](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-09 15.06.52.png)

为了解决该问题，我们可以采用**懒删除（lazy deletion）**机制：它不直接从哈希表中移除元素，**而是利用一个常量 `TOMBSTONE` 来标记这个桶**。在该机制下，`None` 和 `TOMBSTONE` 都代表空桶，都可以放置键值对。但不同的是，线性探测到 `TOMBSTONE` 时应该继续遍历，因为其之下可能还存在键值对。

然而，**懒删除可能会加速哈希表的性能退化**。这是因为每次删除操作都会产生一个删除标记，随着 `TOMBSTONE` 的增加，搜索时间也会增加，因为线性探测可能需要跳过多个 `TOMBSTONE` 才能找到目标元素。

为此，考虑在线性探测中记录遇到的首个 `TOMBSTONE` 的索引，并将搜索到的目标元素与该 `TOMBSTONE` 交换位置。这样做的好处是当每次查询或添加元素时，元素会被移动至距离理想位置（探测起始点）更近的桶，从而优化查询效率。



##### 链式寻址和开放寻址的比较

- 链式地址通过将单个元素转化为链表，将所有冲突元素存储在同一个链表中。然而，链表过长会降低查询效率，可以通过进一步将链表转换为红黑树来提高效率。
- 开放寻址通过多次探测来处理哈希冲突。线性探测使用固定步长，缺点是不能删除元素，且容易产生聚集。多次哈希使用多个哈希函数进行探测，相较线性探测更不易产生聚集，但多个哈希函数增加了计算量。





##### 不同编程语言的不同选择

各种编程语言采取了不同的哈希表实现策略，下面举几个例子。

- Python 采用开放寻址。字典 `dict` 使用伪随机数进行探测。
- Java 采用链式地址。自 JDK 1.8 以来，当 `HashMap` 内数组长度达到 64 且链表长度达到 8 时，链表会转换为红黑树以提升查找性能。
- Go 采用链式地址。Go 规定每个桶最多存储 8 个键值对，超出容量则连接一个溢出桶；当溢出桶过多时，会执行一次特殊的等量扩容操作，以确保性能。





#### 如何减少哈希冲突

前面介绍了哈希表的工作原理和哈希冲突的处理方法。然而无论是开放寻址还是链式地址，**它们只能保证哈希表可以在发生冲突时正常工作，而无法减少哈希冲突的发生**。

哈希冲突的问题出在键值对的分布，而**键值对的分布情况由哈希函数决定**。回忆哈希函数的计算步骤，先计算哈希值，再对数组长度取模：

```
index = hash(key) % capacity
```

观察以上公式，当哈希表容量 `capacity` 固定时，**哈希算法 `hash()` 决定了输出值**，进而决定了键值对在哈希表中的分布情况。

这意味着，为了降低哈希冲突的发生概率，我们应当将注意力集中在哈希算法 `hash()` 的设计上。

...具体如何不必深究







## 树



### 二叉树

#### 初识二叉树

二叉树（binary tree）是一种非线性数据结构，代表“祖先”与“后代”之间的派生关系，体现了“一分为二”的分治逻辑。与链表类似，二叉树的基本单元是节点，每个节点包含值、左子节点引用和右子节点引用。

```python
class TreeNode:
  def __init__(self, val):
    self.val = val
    self.left = None
    self.right = None
```

每个节点都有两个引用（指针），分别指向左子节点（left-child node）和右子节点（right-child node），该节点被称为这两个子节点的父节点（parent node）。如下图，当给定一个二叉树的节点时，我们将该节点的左子节点及其以下节点形成的树称为该节点的左子树（left subtree），同理可得右子树（right subtree）

![截屏2024-10-12 09.33.25](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-12 09.33.25.png)



#### 二叉树常见术语

- 根节点（root node）：位于二叉树顶层的节点，没有父节点。
- 叶节点（leaf node）：没有子节点的节点，其两个指针均指向 `None` 。
- 边（edge）：连接两个节点的线段，即节点引用（指针）。
- 节点所在的层（level）：从顶至底递增，根节点所在层为 1 。
- 节点的度（degree）：节点的子节点的数量。在二叉树中，度的取值范围是 0、1、2 。
- 二叉树的高度（height）：从根节点到最远叶节点所经过的边的数量。
- 节点的深度（depth）：从根节点到该节点所经过的边的数量。
- 节点的高度（height）：从距离该节点最远的叶节点到该节点所经过的边的数量。

![截屏2024-10-12 09.36.18](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-12 09.36.18.png)



#### 二叉树类型

##### 完美二叉树	

完美二叉树（perfect binary tree）所有层的节点都被完全填满。在完美二叉树中，叶节点的度为 0 ，其余所有节点的度都为 2 ；若树的高度为 h ，则节点总数为 2h+1−1 ，呈现标准的指数级关系，反映了自然界中常见的细胞分裂现象。

![截屏2024-10-12 10.15.24](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-12 10.15.24.png)



##### 完全二叉树

完全二叉树（complete binary tree）只有最底层的节点未被填满，且最底层节点尽量靠左填充。请注意，完美二叉树也是一棵完全二叉树

![截屏2024-10-12 10.16.12](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-12 10.16.12.png)



##### 完满二叉树

完满二叉树（full binary tree）除了叶节点之外，其余所有节点都有两个子节点

![截屏2024-10-12 10.17.08](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-12 10.17.08.png)



##### 平衡二叉树

平衡二叉树（balanced binary tree）中任意节点的左子树和右子树的高度之差的绝对值不超过 1 

![截屏2024-10-12 10.19.40](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-12 10.19.40.png)



#### 二叉树的退化

当二叉树的每层节点都被填满时，达到“完美二叉树”；而当所有节点都偏向一侧时，二叉树退化为“链表”。

- 完美二叉树是理想情况，可以充分发挥二叉树“分治”的优势。
- 链表则是另一个极端，各项操作都变为线性操作，时间复杂度退化至 $O(n)$

![截屏2024-10-12 10.22.16](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-12 10.22.16.png)





### 基于链表实现的二叉树



#### 二叉树基本操作

##### 初始二叉树

```python
n1 = TreeNode(val=1)
n2 = TreeNode(val=2)
n3 = TreeNode(val=3)
n4 = TreeNode(val=4)
n5 = TreeNode(val=5)

n1.left = n2
n1.right = n3
n2.left = n4
n2.right = n5
```



##### 插入与删除

与链表类似，在二叉树中插入与删除节点可以通过修改指针来实现, 删除也可以认为是一种特殊的插入

![截屏2024-10-12 09.53.07](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-12 09.53.07.png)

```python
p = TreeNode(0)
# 插入
n1.left = p
p.left = n2
# 删除
n1.left = n2
```





从物理结构的角度来看，树是一种基于链表的数据结构，因此其遍历方式是通过指针逐个访问节点。然而，**树是一种非线性数据结构，这使得遍历树比遍历链表更加复杂，需要借助搜索算法来实现**。



##### 层序遍历（广度优先）

层序遍历（level-order traversal）从顶部到底部逐层遍历二叉树，并在每一层按照从左到右的顺序访问节点。

**层序遍历本质上属于广度优先遍历（breadth-first traversal），也称广度优先搜索（breadth-first search, BFS）**，它体现了一种“一圈一圈向外扩展”的逐层遍历方式。

![截屏2024-10-12 10.27.47](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-12 10.27.47.png)



###### 代码实现

```python
def level_order(root):
  queue = deque()
  queue.append(root)
  
  res = []
  while queue:
    node = queue.popleft()
    res.append(node.val)
    if node.left is not None:
      queue.append(node.left)
    if node.right is not None:
      queue.append(node.right)
  return res
```



###### 复杂度分析

- **时间复杂度为 O(n)** ：所有节点被访问一次，使用 O(n) 时间，其中 n 为节点数量。
- **空间复杂度为 O(n)** ：在最差情况下，即满二叉树时，遍历到最底层之前，队列中最多同时存在 (n+1)/2 个节点，占用 O(n) 空间。



##### 前序，中序，后序遍历（深度优先）

相应地，**前序、中序和后序遍历都属于深度优先遍历（depth-first traversal），也称深度优先搜索（depth-first search, DFS）**，它体现了一种“先走到尽头，再回溯继续”的遍历方式

- [ ] 前序：访问优先级：根节点 -> 左子树 -> 右子树
- [ ] 中序：访问优先级：左子树 -> 根节点 -> 右子树
- [ ] 后序：访问优先级：左子树 -> 右子树 -> 根节点

![截屏2024-10-13 20.36.11](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-13 20.36.11.png)



###### 代码实现

```python
def pre_order(root):
  if root is None:
    return None
  res.append(root.val)
  pre_order(root = root.left)
  pre_order(root = root.right)
  
def in_order(root):
  if root is None:
    return None
  in_order(root = root.left)
  res.append(root.val)
  in_order(root = root.right)
  
def post_order(root):
  if root is None:
    return None
  post_order(root = root.left)
  post_order(root = root.left)
  res.append(root.val)
```



###### 复杂度分析

- **时间复杂度为 O(n)** ：所有节点被访问一次，使用 O(n) 时间。
- **空间复杂度为 O(n)** ：在最差情况下，即树退化为链表时，递归深度达到 n ，系统占用 O(n) 栈帧空间。



### 基于数组实现的二叉树

#### 基于数组实现完美二叉树

给定一棵完美二叉树，我们将所有节点按照层序遍历的顺序存储在一个数组中，则每个节点都对应唯一的数组索引。

根据层序遍历的特性，我们可以推导出父节点索引与子节点索引之间的“映射公式”：**若某节点的索引为 i ，则该节点的左子节点索引为 2i+1 ，右子节点索引为 2i+2** 。下图展示了各个节点索引之间的映射关系。

**映射公式的角色相当于链表中的节点引用（指针）**。给定数组中的任意一个节点，我们都可以通过映射公式来访问它的左（右）子节点。

![截屏2024-10-13 20.13.41](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-13 20.13.41.png)



#### 基于数组实现任意二叉树

完美二叉树是一个特例，在其他类型二叉树的中间层通常存在许多 `None` 。由于层序遍历序列并不包含这些 `None` ，因此我们无法仅凭该序列来推测 `None` 的数量和分布位置。**这意味着存在多种二叉树结构都符合该层序遍历序列**。所以，上述数组表示方法已经失效。

为了解决此问题，**我们可以考虑在层序遍历序列中显式地写出所有 `None`** 。如图所示，这样处理后，层序遍历序列就可以唯一表示二叉树了。示例代码如下：

```python
tree = [1, 2, 3, 4, None, 6, 7, 8, 9, None, None, 12, None, None, 15]
```

![截屏2024-10-13 20.21.43](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-13 20.21.43.png)

值得说明的是，**完全二叉树非常适合使用数组来表示**。回顾完全二叉树的定义，`None` 只出现在最底层且靠右的位置，**因此所有 `None` 一定出现在层序遍历序列的末尾**。

这意味着使用数组表示完全二叉树时，可以省略存储所有 `None` ，非常方便。下图给出了一个例子。

![截屏2024-10-13 20.22.51](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-13 20.22.51.png)





### 二叉搜索树



#### 初识二叉搜索树

如图所示，二叉搜索树（binary search tree）满足以下条件。

1. 对于根节点，左子树中所有节点的值 < 根节点的值 < 右子树中所有节点的值。
2. 任意节点的左、右子树也是二叉搜索树，即同样满足上述的条件

![截屏2024-10-13 21.04.30](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-13 21.04.30.png)



#### 二叉搜索树的常见操作



##### 查找节点

给定目标节点值 `num` ，可以根据二叉搜索树的性质来查找。我们声明一个节点 `cur` ，从二叉树的根节点 `root` 出发，循环比较节点值 `cur.val` 和 `num` 之间的大小关系。

- 若 `cur.val < num` ，说明目标节点在 `cur` 的右子树中，因此执行 `cur = cur.right` 。
- 若 `cur.val > num` ，说明目标节点在 `cur` 的左子树中，因此执行 `cur = cur.left` 。
- 若 `cur.val = num` ，说明找到目标节点，跳出循环并返回该节点。

二叉搜索树的查找操作与二分查找算法的工作原理一致，都是每轮排除一半情况。循环次数最多为二叉树的高度，当二叉树平衡时，使用 $O(log⁡n)$ 时间，代码如下：

```python
def search(self, num: int) -> TreeNode | None:
    """查找节点"""
    cur = self._root
    # 循环查找，越过叶节点后跳出
    while cur is not None:
        # 目标节点在 cur 的右子树中
        if cur.val < num:
            cur = cur.right
        # 目标节点在 cur 的左子树中
        elif cur.val > num:
            cur = cur.left
        # 找到目标节点，跳出循环
        else:
            break
    return cur
```



##### 插入节点

给定一个待插入元素 `num` ，为了保持二叉搜索树“左子树 < 根节点 < 右子树”的性质，插入操作流程如图 7-18 所示。

1. **查找插入位置**：与查找操作相似，从根节点出发，根据当前节点值和 `num` 的大小关系循环向下搜索，直到越过叶节点（遍历至 `None` ）时跳出循环。

2. **在该位置插入节点**：初始化节点 `num` ，将该节点置于 `None` 的位置。

   *二叉搜索树不允许存在重复节点，否则将违反其定义。因此，若待插入节点在树中已存在，则不执行插入，直接返回。*

![截屏2024-10-14 09.28.23](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-14 09.28.23.png)

```python
def insert(self, num):
  if self._root is None:
    self._root = TreeNode(num)
    return 
  cur, pre = self._root, None
  while cur is not None:
    if cur.val == num:
      return
    pre = cur
    
    if cur.val < num:
      cur = cur.right
    else:
      cur = cur.left
      
  node = TreeNode(num)
  if pre.val < num:
    pre.right = node
  else:
    pre.left = node
```

与查找节点相同，插入节点使用 $O(log⁡n)$ 时间



##### 删除节点

先在二叉树中查找到目标节点，再将其删除。与插入节点类似，我们需要保证在删除操作完成后，二叉搜索树的“左子树 < 根节点 < 右子树”的性质仍然满足。因此，我们根据目标节点的子节点数量，分 0、1 和 2 三种情况，执行对应的删除节点操作。

- 当待删除节点的度为 0 时，表示该节点是叶节点，可以直接删除。

![截屏2024-10-14 10.00.04](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-14 10.00.04.png)

- 当待删除节点的度为 1 时，将待删除节点替换为其子节点即可。

![截屏2024-10-14 10.06.34](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-14 10.06.34.png)

- 当待删除节点的度为 2 时，我们无法直接删除它，而需要使用一个节点替换该节点。由于要保持二叉搜索树“左子树 < 根节点 < 右子树”的性质，**因此这个节点可以是右子树的最小节点或左子树的最大节点**。

假设我们选择右子树的最小节点（中序遍历的下一个节点），则删除操作流程如图所示。

1. 找到待删除节点在“中序遍历序列”中的下一个节点，记为 `nex` 。
2. 用 `tmp` 的值覆盖待删除节点的值，并在树中递归删除节点 `nex` 。

![截屏2024-10-14 10.16.05](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-14 10.16.05.png)

![截屏2024-10-14 10.16.34](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-14 10.16.34.png)

![截屏2024-10-14 10.16.45](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-14 10.16.45.png)

删除节点操作同样使用 $O(log⁡n)$ 时间，其中查找待删除节点需要 $O(log⁡n)$ 时间，获取中序遍历后继节点需要 $O(log⁡n)$ 时间



##### 利用中序遍历排序

二叉树的中序遍历遵循“左 → 根 → 右”的遍历顺序，而二叉搜索树满足“左子节点 < 根节点 < 右子节点”的大小关系。

这意味着在二叉搜索树中进行中序遍历时，总是会优先遍历下一个最小节点，从而得出一个重要性质：**二叉搜索树的中序遍历序列是升序的**。

利用中序遍历升序的性质，我们在二叉搜索树中获取有序数据仅需 $O(n)$ 时间，无须进行额外的排序操作，非常高效。

![截屏2024-10-14 10.29.44](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-14 10.29.44.png)



#### 二叉搜索树的效率

|          | 二叉搜索树 |
| :------- | :--------- |
| 查找元素 | $O(log⁡n)$  |
| 插入元素 | $O(log⁡n)$  |
| 删除元素 | $O(log⁡n)$  |

在理想情况下，二叉搜索树是“平衡”的，这样就可以在 $log⁡n$ 轮循环内查找任意节点。

然而，如果我们在二叉搜索树中不断地插入和删除节点，可能导致二叉树退化为链表，这时各种操作的时间复杂度也会退化为 $O(n)$ 



## 堆



### 初识堆

#### 优先队列和堆

需要指出的是，许多编程语言提供的是优先队列（priority queue），这是一种抽象的数据结构，定义为具有优先级排序的队列。

实际上，**堆通常用于实现优先队列，大顶堆相当于元素按从大到小的顺序出队的优先队列**。从使用角度来看，我们**可以将“优先队列”和“堆”看作等价的数据结构**。因此，本书对两者不做特别区分，统一称作“堆”。



#### 堆的常见操作

| 方法名      | 描述                                             | 时间复杂度 |
| :---------- | :----------------------------------------------- | :--------- |
| `push()`    | 元素入堆                                         | $O(log⁡n)$  |
| `pop()`     | 堆顶元素出堆                                     | $O(log⁡n)$  |
| `peek()`    | 访问堆顶元素（对于大 / 小顶堆分别为最大 / 小值） | $O(1)$     |
| `size()`    | 获取堆的元素数量                                 | $O(1)$     |
| `isEmpty()` | 判断堆是否为空                                   | $O(1)$     |

实际应用中，我们可以直接使用编程语言提供的堆类（或优先队列类）。

类似于排序算法中的“从小到大排列”和“从大到小排列”，我们可以通过设置一个 `flag` 或修改 `Comparator` 实现“小顶堆”与“大顶堆”之间的转换。



### 基于数组实现的堆

*下文实现的是大顶堆。若要将其转换为小顶堆，只需将所有大小逻辑判断进行逆转（例如，将 ≥ 替换为 ≤ ）。感兴趣的读者可以自行实现。*

#### 堆是一棵完全二叉树

“二叉树”章节讲过，完全二叉树非常适合用数组来表示。由于堆正是一种完全二叉树，**因此我们将采用数组来存储堆**。

当使用数组表示二叉树时，元素代表节点值，索引代表节点在二叉树中的位置。**节点指针通过索引映射公式来实现**。

如图所示，给定索引 i ，其左子节点的索引为 2i+1 ，右子节点的索引为 2i+2 ，父节点的索引为 (i−1)//2（向下整除）。当索引越界时，表示空节点或节点不存在

![截屏2024-10-16 09.49.39](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-16 09.49.39.png)

```python
def left(self, i: int) -> int:
    """获取左子节点的索引"""
    return 2 * i + 1

def right(self, i: int) -> int:
    """获取右子节点的索引"""
    return 2 * i + 2

def parent(self, i: int) -> int:
    """获取父节点的索引"""
    return (i - 1) // 2  # 向下整除
```



#### 访问堆顶元素

堆顶元素即为二叉树的根节点，也就是列表的首个元素：

```python
def peek(self) -> int:
    """访问堆顶元素"""
    return self.max_heap[0]
```



#### 元素入堆

给定元素 `val` ，我们首先将其添加到堆底。添加之后，由于 `val` 可能大于堆中其他元素，堆的成立条件可能已被破坏，**因此需要修复从插入节点到根节点的路径上的各个节点**，这个操作被称为**堆化（heapify）**

考虑从入堆节点开始，**从底至顶执行堆化**。我们比较插入节点与其父节点的值，如果插入节点更大，则将它们交换。然后继续执行此操作，从底至顶修复堆中的各个节点，直至越过根节点或遇到无须交换的节点时结束。

设节点总数为 n ，则树的高度为 O(log⁡n) 。由此可知，堆化操作的循环轮数最多为 O(log⁡n) ，**元素入堆操作的时间复杂度为 O(log⁡n)** 。代码如下所示：

```python
def push(self, val):
  self.max_heap.append(val)
  self.sift_up(self.size() - 1)
  
def sift_up(self, i):
  while True:
    p = self.parent(i)
    if p < 0 or self.max_heap[i] <= self.max_heap[p]:
      break
    self.swap(i, p)
    i = p
```



#### 堆顶元素出堆

与元素入堆操作相似，堆顶元素出堆操作的时间复杂度也为 O(log⁡n) 。代码如下所示：

```python
def pop(self):
  if self.is _empty():
    raise IndexError("堆为空")
  self.swap(0, self.size() - 1)
  val = self.max_heap.pop()
  self.sift_down(0)
  return val

def sift_down(self, i):
  while True:
    l, r, m = self.left(i), self.right(i), i
    
    if l < slef.size() and self.max_heap[l] > self.max_heap[m]:
      m = l
    if r < self.size() and self.max_heap[r] > self.max_heap[m]:
      m = r
    if m == i:
      break
    
    self.swap(i, m)
    i = m
```



### 建堆操作

#### 借助入堆操作实现

我们首先创建一个空堆，然后遍历列表，依次对每个元素执行“入堆操作”，即先将元素添加至堆的尾部，再对该元素执行“从底至顶”堆化。

每当一个元素入堆，堆的长度就加一。由于节点是从顶到底依次被添加进二叉树的，因此堆是“自上而下”构建的。

设元素数量为 $n$ ，每个元素的入堆操作使用 $O(log⁡n)$ 时间，因此该建堆方法的时间复杂度为 $O(nlog⁡n)$ 



#### 通过遍历堆化实现

实际上，我们可以实现一种更为高效的建堆方法，共分为两步。

1. 将列表所有元素原封不动地添加到堆中，此时堆的性质尚未得到满足。
2. 倒序遍历堆（层序遍历的倒序），依次对每个非叶节点执行“从顶至底堆化”。

**每当堆化一个节点后，以该节点为根节点的子树就形成一个合法的子堆**。而由于是倒序遍历，因此堆是“自下而上”构建的。

之所以选择倒序遍历，是因为这样能够保证当前节点之下的子树已经是合法的子堆，这样堆化当前节点才是有效的。

值得说明的是，**由于叶节点没有子节点，因此它们天然就是合法的子堆，无须堆化**。如以下代码所示，最后一个非叶节点是最后一个节点的父节点，我们从它开始倒序遍历并执行堆化：

```python
def __init__(self, nums: list[int]):
    """构造方法，根据输入列表建堆"""
    # 将列表元素原封不动添加进堆
    self.max_heap = nums
    # 堆化除叶节点以外的其他所有节点
    for i in range(self.parent(self.size() - 1), -1, -1):
        self.sift_down(i)
```



### Top-k 问题













## 图



### 初识图



#### 图是什么

图（graph）是一种非线性数据结构，由顶点（vertex）和边（edge）组成。我们可以将图 G 抽象地表示为一组顶点 V 和一组边 E 的集合。以下示例展示了一个包含 5 个顶点和 7 条边的图。
$$
V={1,2,3,4,5}\\ \\E={(1,2),(1,3),(1,5),(2,3),(2,4),(2,5),(4,5)}\\ \\G={V,E}
$$
如果将顶点看作节点，将边看作连接各个节点的引用（指针），我们就可以将图看作一种从链表拓展而来的数据结构。如图所示，**相较于线性关系（链表）和分治关系（树），网络关系（图）的自由度更高**，因而更为复杂。

![截屏2024-10-17 09.02.27](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 09.02.27.png)



#### 图的常见类型和术语



##### 常见类型

根据边是否具有方向，可分为**无向图**（undirected graph）和**有向图**（directed graph），如图所示。

- 在无向图中，边表示两顶点之间的“双向”连接关系，例如微信或 QQ 中的“好友关系”。
- 在有向图中，边具有方向性，即 $A→B$ 和 $A←B$ 两个方向的边是相互独立的，例如微博或抖音上的“关注”与“被关注”关系。

![截屏2024-10-17 09.05.08](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 09.05.08.png)



根据所有顶点是否连通，可分为**连通图**（connected graph）和**非连通图**（disconnected graph），如图所示。

- 对于连通图，从某个顶点出发，可以到达其余任意顶点。
- 对于非连通图，从某个顶点出发，至少有一个顶点无法到达。

![截屏2024-10-17 09.06.31](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 09.06.31.png)



我们还可以为边添加“权重”变量，从而得到如图所示的有权图（weighted graph）

![截屏2024-10-17 09.08.12](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 09.08.12.png)



##### 术语

图数据结构包含以下常用术语。

- 邻接（adjacency）：当两顶点之间存在边相连时，称这两顶点“邻接”。在图中，顶点 1 的邻接顶点为顶点 2、3、5。
- 路径（path）：从顶点 A 到顶点 B 经过的边构成的序列被称为从 A 到 B 的“路径”。在图中，边序列 1-5-2-4 是顶点 1 到顶点 4 的一条路径。
- 度（degree）：一个顶点拥有的边数。对于有向图，入度（in-degree）表示有多少条边指向该顶点，出度（out-degree）表示有多少条边从该顶点指出。



#### 图的表示



##### 邻接矩阵

邻接矩阵具有以下特性。

- 顶点不能与自身相连，因此邻接矩阵主对角线元素没有意义。
- 对于无向图，两个方向的边等价，此时邻接矩阵关于主对角线对称。
- 将邻接矩阵的元素从 1 和 0 替换为权重，则可表示有权图。

使用邻接矩阵表示图时，我们可以直接访问矩阵元素以获取边，因此增删查改操作的效率很高，时间复杂度均为 $O(1)$ 。然而，矩阵的空间复杂度为 $O(n^2)$ ，内存占用较多。

![截屏2024-10-17 10.19.01](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 10.19.01.png)



### 邻接表

邻接表（adjacency list）使用 n 个链表来表示图，链表节点表示顶点。第 i 个链表对应顶点 i ，其中存储了该顶点的所有邻接顶点（与该顶点相连的顶点）

![截屏2024-10-17 10.19.43](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 10.19.43.png)

邻接表仅存储实际存在的边，而边的总数通常远小于 n2 ，因此它更加节省空间。然而，在邻接表中需要通过遍历链表来查找边，因此其时间效率不如邻接矩阵。

**邻接表结构与哈希表中的“链式地址”非常相似，因此我们也可以采用类似的方法来优化效率**。比如当链表较长时，可以将链表转化为 AVL 树或红黑树，从而将时间效率从 $O(n)$ 优化至 $O(log⁡n)$ ；还可以把链表转换为哈希表，从而将时间复杂度降至 $O(1)$ 



### 图的基本操作

#### 基于邻接矩阵的实现

定一个顶点数量为 n 的无向图，则各种操作的实现方式如图 所示：

- **初始化**：传入 n 个顶点，初始化长度为 n 的顶点列表 `vertices` ，使用 $O(n)$ 时间；初始化 $n×n$ 大小的邻接矩阵 `adjMat` ，使用 $O(n^2)$ 时间。

  ![截屏2024-10-17 10.49.45](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 10.49.45.png)

- **添加或删除边**：直接在邻接矩阵中修改指定的边即可，使用 $O(1)$ 时间。而由于是无向图，因此需要同时更新两个方向的边。

  ![截屏2024-10-17 10.45.13](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 10.45.13.png)

  ![截屏2024-10-17 10.46.44](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 10.46.44.png)

- **添加顶点**：在邻接矩阵的尾部添加一行一列，并全部填 0 即可，使用 $O(n)$ 时间

  ![截屏2024-10-17 10.45.45](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 10.45.45.png)

- **删除顶点**：在邻接矩阵中删除一行一列。当删除首行首列时达到最差情况，需要将 $(n−1)^2$ 个元素“向左上移动”，从而使用 $O(n^2)$ 时间

  ![截屏2024-10-17 10.48.49](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 10.48.49.png)



#### 基于邻接表的实现

设无向图的顶点总数为 n、边总数为 m ，则可根据图 9-8 所示的方法实现各种操作。

- **初始化**：在邻接表中创建 n 个顶点和 2m 条边，使用 O(n+m) 时间

  ![截屏2024-10-17 11.35.29](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 11.35.29.png)

- **添加边**：在顶点对应链表的末尾添加边即可，使用 O(1) 时间。因为是无向图，所以需要同时添加两个方向的边。

  ![截屏2024-10-17 11.36.08](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 11.36.08.png)

- **删除边**：在顶点对应链表中查找并删除指定边，使用 O(m) 时间。在无向图中，需要同时删除两个方向的边。

  ![截屏2024-10-17 11.36.34](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 11.36.34.png)

- **添加顶点**：在邻接表中添加一个链表，并将新增顶点作为链表头节点，使用 O(1) 时间。

  ![截屏2024-10-17 11.37.08](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 11.37.08.png)

- **删除顶点**：需遍历整个邻接表，删除包含指定顶点的所有边，使用 O(n+m) 时间。

  ![截屏2024-10-17 11.37.24](/Users/aris/Library/Application Support/typora-user-images/截屏2024-10-17 11.37.24.png)







#### 效率对比

设图中共有 n 个顶点和 m 条边，下表对比了邻接矩阵和邻接表的时间效率和空间效率。

|              | 邻接矩阵 | 邻接表（链表） | 邻接表（哈希表） |
| :----------- | :------- | :------------- | :--------------- |
| 判断是否邻接 | O(1)     | O(m)           | O(1)             |
| 添加边       | O(1)     | O(1)           | O(1)             |
| 删除边       | O(1)     | O(m)           | O(1)             |
| 添加顶点     | O(n)     | O(1)           | O(1)             |
| 删除顶点     | O(n2)    | O(n+m)         | O(n)             |
| 内存空间占用 | O(n2)    | O(n+m)         | O(n+m)           |

观察表，似乎邻接表（哈希表）的时间效率与空间效率最优。但实际上，在邻接矩阵中操作边的效率更高，只需一次数组访问或赋值操作即可。综合来看，邻接矩阵体现了“以空间换时间”的原则，而邻接表体现了“以时间换空间”的原则。



### 图的遍历







